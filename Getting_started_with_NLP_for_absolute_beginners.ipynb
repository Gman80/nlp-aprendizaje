{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 33657,
          "databundleVersionId": 3279164,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30177,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Getting started with NLP for absolute beginners",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f7b9f6727124f82873233ba61518c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64f7b588b3564268ab97c9e74f9abf70"
            ],
            "layout": "IPY_MODEL_726afefeba42468ca26003409e7313f5"
          }
        },
        "15d42a9d9e33477bab321941d29c0763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e841549e844ebdb352e8718409fef8",
            "placeholder": "​",
            "style": "IPY_MODEL_b66eccddefa64f78be773ed43f5fdd9f",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "8582a4b108fb4afdb5c3be8fc968991d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3bd009b771534f30a4c79938ef9edc07",
            "placeholder": "​",
            "style": "IPY_MODEL_17dc606f6afe43a6b5aceb1184ba3c33",
            "value": "gmanricamerordoez"
          }
        },
        "5c0507b7252a45258370b4cde9601d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6960b80ff0514ce6b18d59159db9c1da",
            "placeholder": "​",
            "style": "IPY_MODEL_879b7facd7634036945231ab464a899b",
            "value": ""
          }
        },
        "b3e61eb55ffa4dd6b89ce8eaece8ecdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dedbc5a5c0f14d28b1d02591a4ed9390",
            "style": "IPY_MODEL_fc389b6d340c4613bf40aa6b90776d45",
            "tooltip": ""
          }
        },
        "912b9ea2f0a84569bc993b9de686314b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc100b2385d4fdf8e224208684afd5e",
            "placeholder": "​",
            "style": "IPY_MODEL_0013986f79244bc49fe655f2e31c92a3",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "726afefeba42468ca26003409e7313f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a2e841549e844ebdb352e8718409fef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66eccddefa64f78be773ed43f5fdd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bd009b771534f30a4c79938ef9edc07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17dc606f6afe43a6b5aceb1184ba3c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6960b80ff0514ce6b18d59159db9c1da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879b7facd7634036945231ab464a899b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dedbc5a5c0f14d28b1d02591a4ed9390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc389b6d340c4613bf40aa6b90776d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3cc100b2385d4fdf8e224208684afd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0013986f79244bc49fe655f2e31c92a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7822db8de1ca4cd695fac036ed61ecae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97350345143f44c9935d3cffedb5d755",
            "placeholder": "​",
            "style": "IPY_MODEL_87b6de24c2724e0198c1bf8a4d5250bf",
            "value": "Connecting..."
          }
        },
        "97350345143f44c9935d3cffedb5d755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b6de24c2724e0198c1bf8a4d5250bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f7b588b3564268ab97c9e74f9abf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0122974f39436eaad6aad1bf66c43c",
            "placeholder": "​",
            "style": "IPY_MODEL_c637f8f226d44acbac636a7c0170015c",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "bb0122974f39436eaad6aad1bf66c43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c637f8f226d44acbac636a7c0170015c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gman80/nlp-aprendizaje/blob/main/Getting_started_with_NLP_for_absolute_beginners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Ut0GranyJpnO",
        "outputId": "7531bf67-2932-434d-da2e-6e92076ee9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "3f7b9f6727124f82873233ba61518c3d",
            "15d42a9d9e33477bab321941d29c0763",
            "8582a4b108fb4afdb5c3be8fc968991d",
            "5c0507b7252a45258370b4cde9601d14",
            "b3e61eb55ffa4dd6b89ce8eaece8ecdd",
            "912b9ea2f0a84569bc993b9de686314b",
            "726afefeba42468ca26003409e7313f5",
            "a2e841549e844ebdb352e8718409fef8",
            "b66eccddefa64f78be773ed43f5fdd9f",
            "3bd009b771534f30a4c79938ef9edc07",
            "17dc606f6afe43a6b5aceb1184ba3c33",
            "6960b80ff0514ce6b18d59159db9c1da",
            "879b7facd7634036945231ab464a899b",
            "dedbc5a5c0f14d28b1d02591a4ed9390",
            "fc389b6d340c4613bf40aa6b90776d45",
            "3cc100b2385d4fdf8e224208684afd5e",
            "0013986f79244bc49fe655f2e31c92a3",
            "7822db8de1ca4cd695fac036ed61ecae",
            "97350345143f44c9935d3cffedb5d755",
            "87b6de24c2724e0198c1bf8a4d5250bf",
            "64f7b588b3564268ab97c9e74f9abf70",
            "bb0122974f39436eaad6aad1bf66c43c",
            "c637f8f226d44acbac636a7c0170015c"
          ]
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f7b9f6727124f82873233ba61518c3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "us_patent_phrase_to_phrase_matching_path = kagglehub.competition_download('us-patent-phrase-to-phrase-matching')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "XSDyfw3EJpnP",
        "outputId": "18f4209a-b287-4c65-9bd7-e21b979b577d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/us-patent-phrase-to-phrase-matching...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 682k/682k [00:00<00:00, 60.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Data source import complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Kaggle link: https://www.kaggle.com/code/prasanth07/getting-started-with-nlp-for-absolute-beginners/\n",
        "* GitHub link: https://github.com/prasanth-ntu/fastai-course22/blob/master/kaggle_notebooks/getting-started-with-nlp-for-absolute-beginners.ipynb\n",
        "\n",
        "*Note*: Using kaggle notebook as we need GPU to train the model"
      ],
      "metadata": {
        "id": "6raHHUlCJpnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "G_t00jowJpnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One area where deep learning has dramatically improved in the last couple of years is natural language processing (NLP). Computers can now generate text, translate automatically from one language to another, analyze comments, label words in sentences, and much more.\n",
        "\n",
        "Perhaps the most widely practically useful application of NLP is *classification* -- that is, classifying a document automatically into some category. This can be used, for instance, for:\n",
        "\n",
        "- Sentiment analysis (e.g are people saying *positive* or *negative* things about your product)\n",
        "- Author identification (what author most likely wrote some document)\n",
        "- Legal discovery (which documents are in scope for a trial)\n",
        "- Organizing documents by topic\n",
        "- Triaging inbound emails\n",
        "- ...and much more!\n",
        "\n",
        "Classification models can also be used to solve problems that are not, at first, obviously appropriate. For instance, consider the Kaggle [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/) competition. In this, we are tasked with comparing two words or short phrases, and scoring them based on whether they're similar or not, based on which patent class they were used in. With a score of `1` it is considered that the two inputs have identical meaning, and `0` means they have totally different meaning. For instance, *abatement* and *eliminating process* have a score of `0.5`, meaning they're somewhat similar, but not identical.\n",
        "\n",
        "It turns out that this can be represented as a classification problem. How? By representing the question like this:\n",
        "\n",
        "> For the following text...: \"TEXT1: abatement; TEXT2: eliminating process\" ...chose a category of meaning similarity: \"Different; Similar; Identical\".\n",
        "\n",
        "In this notebook we'll see how to solve the Patent Phrase Matching problem by treating it as a classification task, by representing it in a very similar way to that shown above."
      ],
      "metadata": {
        "id": "NHPjnq17JpnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traducción:\n",
        "\n",
        "En esto, tenemos la tarea de comparar dos palabras o frases cortas y calificarlas en función de si son similares o no, según la clase de patente en la que se usaron.\n",
        "\n",
        "Por ejemplo, *reducción* y *proceso de eliminación* tienen una puntuación de \"0,5\", lo que significa que son algo similares, pero no idénticos.\n",
        "\n",
        "Resulta que esto puede representarse como un problema de clasificación. ¿Cómo? Representando la pregunta de esta manera:\n",
        "\n",
        "> Para el siguiente texto...: \"TEXTO1: abatimiento; TEXTO2: proceso de eliminación\" ...seleccionó una categoría de similitud de significado: \"Diferente; Similar; Idéntico\"."
      ],
      "metadata": {
        "id": "45ypMdm1JpnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On Kaggle"
      ],
      "metadata": {
        "id": "8COCuKufJpnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle is an awesome resource for aspiring data scientists or anyone looking to improve their machine learning skills. There is nothing like being able to get hands-on practice and receiving real-time feedback to help you improve your skills. It provides:\n",
        "\n",
        "1. Interesting data sets\n",
        "1. Feedback on how you're doing\n",
        "1. A leader board to see what's good, what's possible, and what's state-of-art\n",
        "1. Notebooks and blog posts by winning contestants share useful tips and techniques.\n",
        "\n",
        "The dataset we will be using here is only available from Kaggle. Therefore, you will need to register on the site, then go to the [page for the competition](https://www.kaggle.com/c/us-patent-phrase-to-phrase-matching). On that page click \"Rules,\" then \"I Understand and Accept.\" (Although the competition has finished, and you will not be entering it, you still have to agree to the rules to be allowed to download the data.)\n",
        "\n",
        "There are two ways to then use this data:\n",
        "\n",
        "- Easiest: run this notebook directly on Kaggle, or\n",
        "- Most flexible: download the data locally and run it on your PC or GPU server\n",
        "\n",
        "If you are running this on Kaggle.com, you can skip the next section. Just make sure that on Kaggle you've selected to use a GPU during your session, by clicking on the hamburger menu (3 dots in the top right) and clicking \"Accelerator\" -- it should look like this:"
      ],
      "metadata": {
        "id": "A0149iF2JpnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traducción:\n",
        "\n",
        "Kaggle es un recurso increíble para los aspirantes a científicos de datos o cualquiera que busque mejorar sus habilidades de aprendizaje automático. No hay nada como poder practicar y recibir comentarios en tiempo real para ayudarlo a mejorar sus habilidades. Proporciona:\n",
        "\n",
        "1 Conjuntos de datos interesantes\n",
        "2 Comentarios sobre cómo te va\n",
        "3 Una tabla de clasificación para ver qué es bueno, qué es posible y qué es lo último en tecnología\n",
        "4 Los cuadernos y publicaciones de blogs de los concursantes ganadores comparten consejos y técnicas útiles.\n",
        "\n",
        "El conjunto de datos que usaremos aquí solo está disponible en Kaggle. Por lo tanto, deberá registrarse en el sitio y luego ir a la página del concurso. En esa página, haga clic en \"Reglas\" y luego en \"Entiendo y acepto\". (Aunque la competencia ha finalizado y usted no participará, aún debe aceptar las reglas para poder descargar los datos).\n",
        "\n",
        "Hay dos formas de utilizar estos datos:\n",
        "- Más fácil: ejecute este cuaderno directamente en Kaggle, o\n",
        "- Más flexible: descargue los datos localmente y ejecútelos en su PC o servidor GPU\n",
        "\n",
        "\n",
        "\n",
        "Si está ejecutando esto en Kaggle.com, puede omitir la siguiente sección. Solo asegúrate de que en Kaggle hayas seleccionado usar una GPU durante tu sesión, haciendo clic en el menú de hamburguesas (3 puntos en la parte superior derecha) y haciendo clic en \"Acelerador\". Debería verse así:"
      ],
      "metadata": {
        "id": "DbBpgFDpJpnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:9af4e875-1f2a-468c-b233-8c91531e4c40.png)!"
      ],
      "metadata": {
        "id": "Vxs8cPYNJpnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll need slightly different code depending on whether we're running on Kaggle or not, so we'll use this variable to track where we are:"
      ],
      "metadata": {
        "id": "tFP_-UTeJpnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traduccion:\n",
        "Necesitaremos un código ligeramente diferente dependiendo de si estamos ejecutando Kaggle o no, por lo que usaremos esta variable para rastrear dónde estamos:"
      ],
      "metadata": {
        "id": "5rEfHqwnJpnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
      ],
      "metadata": {
        "trusted": true,
        "id": "1k919cs3JpnS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Kaggle data on your own machine"
      ],
      "metadata": {
        "id": "41zbe-hRJpnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle limits your weekly time using a GPU machine. The limits are very generous, but you may well still find it's not enough! In that case, you'll want to use your own GPU server, or a cloud server such as Colab, Paperspace Gradient, or SageMaker Studio Lab (all of which have free options). To do so, you'll need to be able to download Kaggle datasets.\n",
        "\n",
        "The easiest way to download Kaggle datasets is to use the Kaggle API. You can install this using `pip` by running this in a notebook cell:\n",
        "\n",
        "    !pip install kaggle\n",
        "\n",
        "You need an API key to use the Kaggle API; to get one, click on your profile picture on the Kaggle website, and choose My Account, then click Create New API Token. This will save a file called *kaggle.json* to your PC. You need to copy this key on your GPU server. To do so, open the file you downloaded, copy the contents, and paste them in the following cell (e.g., `creds = '{\"username\":\"xxx\",\"key\":\"xxx\"}'`):"
      ],
      "metadata": {
        "id": "_FrJn2yKJpnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traduccion:\n",
        "\n",
        "Kaggle limita su tiempo semanal usando una máquina GPU. Los límites son muy generosos, ¡pero es posible que aun así descubras que no son suficientes! En ese caso, querrás utilizar tu propio servidor GPU o un servidor en la nube como Colab, Paperspace Gradient o SageMaker Studio Lab (todos los cuales tienen opciones gratuitas). Para hacerlo, deberá poder descargar conjuntos de datos de Kaggle.\n",
        "\n",
        "La forma más sencilla de descargar conjuntos de datos de Kaggle es utilizar la API de Kaggle. Puedes instalar esto usando pip ejecutando esto en una celda de notebook:\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "Necesita una clave API para utilizar la API de Kaggle; Para obtener uno, haga clic en su foto de perfil en el sitio web de Kaggle, elija Mi cuenta y luego haga clic en Crear nuevo token API. Esto guardará un archivo llamado *kaggle.json* en su PC. Debe copiar esta clave en su servidor GPU. Para hacerlo, abra el archivo que descargó, copie el contenido y péguelo en la siguiente celda(e.g., `creds = '{\"username\":\"xxx\",\"key\":\"xxx\"}'`):"
      ],
      "metadata": {
        "id": "XDkabyjXJpnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creds = '{\"username\":\"gmanricamerordoez\",\"key\":\"a2221b674be1cf5765d715f95a09e0c0\"}'"
      ],
      "metadata": {
        "trusted": true,
        "id": "0hQQG8XmJpnT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then execute this cell (this only needs to be run once):"
      ],
      "metadata": {
        "id": "C26bHZjqJpnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for working with paths in Python, I recommend using `pathlib.Path`\n",
        "from pathlib import Path\n",
        "\n",
        "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
        "if not cred_path.exists():\n",
        "    cred_path.parent.mkdir(exist_ok=True)\n",
        "    cred_path.write_text(creds)\n",
        "    cred_path.chmod(0o600)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FK-xTyAUJpnU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can download datasets from Kaggle."
      ],
      "metadata": {
        "id": "hciPk7jlJpnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('us-patent-phrase-to-phrase-matching')"
      ],
      "metadata": {
        "trusted": true,
        "id": "5F6DOCQnJpnU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "And use the Kaggle API to download the dataset to that path, and extract it:"
      ],
      "metadata": {
        "id": "CFlVioVUJpnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not iskaggle and not path.exists():\n",
        "    import zipfile,kaggle\n",
        "    kaggle.api.competition_download_cli(str(path))\n",
        "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8gdqAbt_JpnU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that you can easily download notebooks from Kaggle and upload them to other cloud services. So if you're low on Kaggle GPU credits, give this a try!"
      ],
      "metadata": {
        "id": "1aVNSADWJpnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traducción:\n",
        "Tenga en cuenta que puede descargar fácilmente cuadernos de Kaggle y cargarlos en otros servicios en la nube. Entonces, si tienes pocos créditos de GPU Kaggle, ¡pruébalo!"
      ],
      "metadata": {
        "id": "6ih_xWv_JpnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and EDA"
      ],
      "metadata": {
        "id": "nl3VbX4iJpnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if iskaggle:\n",
        "    path = Path('../input/us-patent-phrase-to-phrase-matching')\n",
        "    ! pip install -q datasets"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dqa8gVMFJpnV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documents in NLP datasets are generally in one of two main forms:\n",
        "\n",
        "- **Larger documents**: One text file per document, often organised into one folder per category\n",
        "- **Smaller documents**: One document (or document pair, optionally with metadata) per row in a [CSV file](https://realpython.com/python-csv/).\n",
        "\n",
        "Let's look at our data and see what we've got. In Jupyter you can use any bash/shell command by starting a line with a `!`, and use `{}` to include python variables, like so:"
      ],
      "metadata": {
        "id": "4O_8t40SJpnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traduccion:\n",
        "Los documentos en los conjuntos de datos de PNL generalmente se encuentran en una de dos formas principales:\n",
        "\n",
        "- **Documentos más grandes**: un archivo de texto por documento, a menudo organizado en una carpeta por categoría\n",
        "- **Documentos más pequeños**: un documento (o par de documentos, opcionalmente con metadatos) por fila en un [archivo CSV](https://realpython.com/python-csv/).\n",
        "\n",
        "Miremos nuestros datos y veamos qué tenemos. En Jupyter puedes usar cualquier comando bash/shell comenzando una línea con `!` y usar `{}` para incluir variables de Python, así:"
      ],
      "metadata": {
        "id": "j0sYr6p0JpnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {path}"
      ],
      "metadata": {
        "trusted": true,
        "id": "Gb_hi9kUJpnV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like this competition uses CSV files. For opening, manipulating, and viewing CSV files, it's generally best to use the Pandas library, which is explained brilliantly in [this book](https://wesmckinney.com/book/) by the lead developer (it's also an excellent introduction to matplotlib and numpy, both of which I use in this notebook). Generally it's imported as the abbreviation `pd`."
      ],
      "metadata": {
        "id": "9aGW5ZqoJpnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traduccion:\n",
        "\n",
        "Parece que este concurso utiliza archivos CSV. Para abrir, manipular y ver archivos CSV, generalmente es mejor usar la biblioteca Pandas, que el desarrollador principal explica brillantemente en [este libro](https://wesmckinney.com/book/) (también es una excelente introducción). a matplotlib y numpy, los cuales uso en este cuaderno). Generalmente se importa como la abreviatura \"pd\"."
      ],
      "metadata": {
        "id": "N_k7QOgkJpnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "id": "wO-fxYhEJpnW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set a path to our data:"
      ],
      "metadata": {
        "id": "cLfnF77IJpnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "MPxBXqo9JpnW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "RhLgICT7JpnW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a [DataFrame](https://pandas.pydata.org/docs/user_guide/10min.html), which is a table of named columns, a bit like a database table. To view the first and last rows, and row count of a DataFrame, just type its name:"
      ],
      "metadata": {
        "id": "hiWHAochJpnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traducción:\n",
        "\n",
        "Esto crea un [DataFrame](https://pandas.pydata.org/docs/user_guide/10min.html), que es una tabla de columnas con nombre, un poco como una tabla de base de datos. Para ver la primera y la última fila, y el recuento de filas de un DataFrame, simplemente escriba su nombre:"
      ],
      "metadata": {
        "id": "jsBw-nhZJpnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "trusted": true,
        "id": "A0ix7KbLJpnW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to carefully read the [dataset description](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/data) to understand how each of these columns is used.\n",
        "\n",
        "One of the most useful features of `DataFrame` is the `describe()` method:"
      ],
      "metadata": {
        "id": "6Ab7NWRVJpna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='object')"
      ],
      "metadata": {
        "trusted": true,
        "id": "oBej5L85Jpna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in the 36473 rows, there are 733 unique anchors, 106 contexts, and nearly 30000 targets. Some anchors are very common, with \"component composite coating\" for instance appearing 152 times.\n",
        "\n",
        "Earlier, I suggested we could represent the input to the model as something like \"*TEXT1: abatement; TEXT2: eliminating process*\". We'll need to add the context to this too. In Pandas, we just use `+` to concatenate, like so:"
      ],
      "metadata": {
        "id": "OmdtzQZVJpna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traducción:\n",
        "\n",
        "Podemos ver que en las 36473 filas, hay 733 anclajes únicos, 106 contextos y casi 30000 objetivos. Algunos anclajes son muy comunes; por ejemplo, el \"revestimiento compuesto de componentes\" aparece 152 veces.\n",
        "\n",
        "Anteriormente, sugerí que podríamos representar la entrada al modelo como algo así como \"*TEXTO1: reducción; TEXTO2: proceso de eliminación*\". También necesitaremos agregar el contexto a esto. En Pandas, simplemente usamos `+` para concatenar, así:"
      ],
      "metadata": {
        "id": "Moyklx7tJpna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor"
      ],
      "metadata": {
        "trusted": true,
        "id": "Gldx5nwdJpnb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\">**Why do we concatenate the `input` from multiple columns with headers?**</span>\n",
        "* Otherwise, it would not know where the `context` ended and `target` started. Likewise, it would also not know where the `target` ended and `anchor` started\n",
        "* Instead of `TEXTX`, we could have also used other delimiters to help NN differentiate them."
      ],
      "metadata": {
        "id": "LgcKvEr3Jpnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\">**¿Por qué concatenamos la `entrada` de varias columnas con encabezados?**</span>\n",
        "* De lo contrario, no sabría dónde termina el \"contexto\" y dónde comienza el \"objetivo\". Del mismo modo, tampoco sabría dónde termina el \"objetivo\" y comienza el \"ancla\".\n",
        "* En lugar de `TEXTX`, también podríamos haber usado otros delimitadores para ayudar a NN a diferenciarlos."
      ],
      "metadata": {
        "id": "JCyVslDpJpnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can refer to a column (also known as a *series*) either using regular python \"dotted\" notation, or access it like a dictionary. To get the first few rows, use `head()`:"
      ],
      "metadata": {
        "id": "u62oydo0Jpnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos referirnos a una columna (también conocida como *serie*) ya sea usando la notación \"punteada\" normal de Python o accediendo a ella como un diccionario. Para obtener las primeras filas, use `head()`:"
      ],
      "metadata": {
        "id": "7EB7Sfv2Jpnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.input.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "QRKky1WYJpnb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.input.iloc[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "lxvSwaAaJpnb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "sXrdfaKKJpnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers uses a `Dataset` object for storing a... well a dataset, of course! We can create one like so:"
      ],
      "metadata": {
        "id": "iGY7i-4lJpnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers usa un objeto `Dataset` para almacenar un... bueno, un conjunto de datos, ¡por supuesto! Podemos crear uno así"
      ],
      "metadata": {
        "id": "qmu3RrjqJpnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset,DatasetDict # From Hugging Face, and is different from fastai datasets\n",
        "\n",
        "ds = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DEdN7F4FJpnc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how it's displayed in a notebook:"
      ],
      "metadata": {
        "id": "tFT7dFgJJpnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "trusted": true,
        "id": "0Pud02V2Jpnc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(ds))"
      ],
      "metadata": {
        "trusted": true,
        "id": "gebzjKf0Jpnc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y4SK1CT1Jpnc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds.info"
      ],
      "metadata": {
        "trusted": true,
        "id": "0e29LpCYJpnc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "But <span  style=\"color:red\">we can't pass the texts directly into a model</span>. **A deep learning model expects numbers as inputs, not English sentences**! So we need to do two things:\n",
        "\n",
        "- <span style=\"color:blue\"><b>*Tokenization*:</b> Split each text up into words (or actually, as we'll see, into *tokens*)</span>\n",
        "- <span style=\"color:blue\"><b>*Numericalization*</b>: Convert each word (or token) into a number.</span>\n",
        "\n",
        "**The details about how this is done actually depend on the particular model we use**. So first we'll need to pick a model. <span style=\"color:blue\">There are thousands of models available, but a reasonable starting point for nearly any NLP problem is to use this (replace \"small\" with \"large\" for a slower but more accurate model, once you've finished exploring)</span>:"
      ],
      "metadata": {
        "id": "7zjkRmtyJpnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pero <span style=\"color:red\">no podemos pasar los textos directamente a un modelo</span>. **¡Un modelo de aprendizaje profundo espera números como entradas, no oraciones en inglés**! Entonces necesitamos hacer dos cosas:\n",
        "\n",
        "- <span style=\"color:blue\"><b>*Tokenización*:</b> Divide cada texto en palabras (o en realidad, como veremos, en *tokens*)</span>\n",
        "- <span style=\"color:blue\"><b>*Numericalización*</b>: convierte cada palabra (o token) en un número.</span>\n",
        "\n",
        "**Los detalles sobre cómo se hace esto en realidad dependen del modelo particular que usemos**. Entonces, primero tendremos que elegir un modelo. <span style=\"color:blue\">Hay miles de modelos disponibles, pero un punto de partida razonable para casi cualquier problema de PNL es utilizar este (reemplace \"pequeño\" por \"grande\" para obtener un modelo más lento pero más preciso, una vez que He terminado de explorar)</span>:\n",
        "\n"
      ],
      "metadata": {
        "id": "jsP3IlyXJpnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging face has 1000s of pretrained models. Even for patents, there are 150 models (https://huggingface.co/models?sort=downloads&search=patent) as of Jun 2023. So, we can even quickly start with pretrained models.\n",
        "\n",
        "However, we will use a generic model `microsoft/deberta-v2-small` ([link](https://huggingface.co/models?sort=downloads&search=deberta-v3-small)), which are generally good for broad range of things."
      ],
      "metadata": {
        "id": "tMQxVctzJpnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_nm = 'microsoft/deberta-v3-small'"
      ],
      "metadata": {
        "trusted": true,
        "id": "0mqjERvuJpnd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AutoTokenizer` will create a tokenizer appropriate for a given model:\n",
        "- To tell Transformers that we want to tokenize the same way that people built the model did"
      ],
      "metadata": {
        "id": "7Few9PI5Jpnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "`AutoTokenizer` creará un tokenizador apropiado para un modelo determinado:\n",
        "- Para decirle a Transformers que queremos tokenizar de la misma manera que la gente construyó el modelo."
      ],
      "metadata": {
        "id": "ltIloMotJpnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_MEQWXiFJpnd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of how the <span style=\"color:blue\">tokenizer splits a text into \"tokens\" (which are like words, but can be sub-word pieces)</span>, as you see below:\n",
        "- Kind of putting into words, kind of not\n",
        "- e.g.,\n",
        "    - `G'day` - 3 tokens\n",
        "    - `I'm` - 3 tokens"
      ],
      "metadata": {
        "id": "iOtITCFpJpnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se muestra un ejemplo de cómo el <span style=\"color:blue\">tokenizador divide un texto en \"tokens\" (que son como palabras, pero pueden ser partes de subpalabras)</span>, como se ve a continuación:\n",
        "- Más o menos expresado en palabras, más o menos no.\n",
        "- e.g.,\n",
        "    - `G'day` - 3 tokens\n",
        "    - `I'm` - 3 tokens"
      ],
      "metadata": {
        "id": "plmcxF4uJpnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.tokenize(\"G'day folks, I'm Jeremy from fast.ai!\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MjRXZKVbJpne"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncommon words will be split into pieces. <span style=\"color:blue\">The start of a new word is represented by `▁`:</span>"
      ],
      "metadata": {
        "id": "Dfs0ly4AJpne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las palabras poco comunes se dividirán en pedazos. <span style=\"color:blue\">El comienzo de una nueva palabra está representado por `_`:</span>"
      ],
      "metadata": {
        "id": "i8lfgyxuJpne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.tokenize(\"A platypus is an ornithorhynchus anatinus.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fpw1e7n0Jpne"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a simple function which tokenizes our inputs:"
      ],
      "metadata": {
        "id": "TZrNy01fJpne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(x): return tokz(x[\"input\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "d-aS1SxgJpne"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this quickly in parallel on every row in our dataset, use `map`:"
      ],
      "metadata": {
        "id": "UHbf-U-3Jpne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ejecutar esto rápidamente en paralelo en cada fila de nuestro conjunto de datos, use `map`:"
      ],
      "metadata": {
        "id": "vvip81vLJpnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok_ds = ds.map(tok_func, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_KnWCTNEJpnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This adds a new item to our dataset called `input_ids`. For instance, here is the input and IDs for the first row of our data:"
      ],
      "metadata": {
        "id": "vg--DpsRJpnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto agrega un nuevo elemento a nuestro conjunto de datos llamado `input_ids`. Por ejemplo, aquí están la entrada y los ID de la primera fila de nuestros datos:"
      ],
      "metadata": {
        "id": "TXkhF9ijJpnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (ds.shape)\n",
        "ds"
      ],
      "metadata": {
        "trusted": true,
        "id": "WvwC_AObJpnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print (tok_ds.shape)\n",
        "tok_ds"
      ],
      "metadata": {
        "trusted": true,
        "id": "R-NYMIYHJpnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "row = tok_ds[0]\n",
        "row['input'], row['input_ids']"
      ],
      "metadata": {
        "trusted": true,
        "id": "FbUdgosOJpnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in row.items():\n",
        "    print (f\"row[{x:>20s}]: {y}\")\n",
        "print (\"-\"*20)\n",
        "print (len(row[\"input_ids\"]), len(row[\"token_type_ids\"]), len(row[\"attention_mask\"]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "l1gyoxnwJpnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.tokenize(row[\"input\"]), len(tokz.tokenize(row[\"input\"]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "8AjaAmUwJpnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what are those IDs and where do they come from? The secret is that there's a list called `vocab` in the tokenizer which contains a unique integer for every possible token string. We can look them up like this, for instance to find the token for the word \"of\":"
      ],
      "metadata": {
        "id": "OkAWkMx8Jpng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entonces, ¿qué son esas identificaciones y de dónde vienen? El secreto es que hay una lista llamada \"vocab\" en el tokenizador que contiene un número entero único para cada cadena de token posible. Podemos buscarlos así, por ejemplo para encontrar el token de la palabra \"of\":"
      ],
      "metadata": {
        "id": "WiqbLjLuJpng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.vocab['▁of'], tokz.vocab['▁TEXT']"
      ],
      "metadata": {
        "trusted": true,
        "id": "c7nTd4nDJpng"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking above at our input IDs, we do indeed see that `265` appears as expected.\n",
        "\n",
        "Finally, we need to prepare our labels. **Transformers always assumes that your labels has the column name `labels`**, but in our dataset it's currently `score`. Therefore, we need to rename it:"
      ],
      "metadata": {
        "id": "bdfEO2tfJpng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al mirar arriba nuestros ID de entrada, vemos que \"265\" aparece como se esperaba.\n",
        "\n",
        "Finalmente, necesitamos preparar nuestras etiquetas. **Transformers siempre asume que sus etiquetas tienen el nombre de columna \"labels\" **, pero en nuestro conjunto de datos actualmente es \"score\". Por lo tanto, debemos cambiarle el nombre:"
      ],
      "metadata": {
        "id": "7REwt--aJpng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok_ds = tok_ds.rename_columns({'score':'labels'})"
      ],
      "metadata": {
        "trusted": true,
        "id": "t19VuKyTJpng"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've prepared our tokens and labels, we need to create our validation set."
      ],
      "metadata": {
        "id": "bw8TX8JJJpng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test and validation sets"
      ],
      "metadata": {
        "id": "_YiyMDOyJpng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may have noticed that our directory contained another file:"
      ],
      "metadata": {
        "id": "BE_ApI2kJpng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.read_csv(path/'test.csv')\n",
        "eval_df.describe()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ItVqI9bvJpng"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the *test set*. Possibly the most important idea in machine learning is that of having separate training, validation, and test data sets."
      ],
      "metadata": {
        "id": "YPBHcqPFJpng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este es el *conjunto de prueba*. Posiblemente la idea más importante en el aprendizaje automático es la de tener conjuntos de datos de prueba, validación y entrenamiento separados."
      ],
      "metadata": {
        "id": "F-KAUFoQJpnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation set"
      ],
      "metadata": {
        "heading_collapsed": true,
        "id": "iN61m3MEJpnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explain the motivation, let's start simple, and imagine we're trying to fit a model where the true relationship is this quadratic:"
      ],
      "metadata": {
        "hidden": true,
        "id": "8DZHz0cXJpnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para explicar la motivación, comencemos de manera simple e imaginemos que estamos tratando de ajustar un modelo donde la verdadera relación es esta cuadrática:"
      ],
      "metadata": {
        "id": "2ZUKUvRDJpnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x): return -3*x**2 + 2*x + 20"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "8_NO25dqJpnh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately matplotlib (the most common library for plotting in Python) doesn't come with a way to visualize a function, so we'll write something to do this ourselves:"
      ],
      "metadata": {
        "hidden": true,
        "id": "vn85IEYYJpnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desafortunadamente, matplotlib (la biblioteca más común para trazar en Python) no viene con una forma de visualizar una función, por lo que escribiremos algo para hacerlo nosotros mismos:"
      ],
      "metadata": {
        "id": "mZBYSIheJpnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "def plot_function(f, min=-2.1, max=2.1, color='r'):\n",
        "    x = np.linspace(min,max, 100)[:,None]\n",
        "    plt.plot(x, f(x), color)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "U0c3mbsTJpnh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's what our function looks like:"
      ],
      "metadata": {
        "hidden": true,
        "id": "jpeiASS5Jpnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_function(f)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "sPyAX9UQJpnh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance, perhaps we've measured the height above ground of an object before and after some event. The measurements will have some random error. We can use numpy's random number generator to simulate that. I like to use `seed` when writing about simulations like this so that I know you'll see the same thing I do:"
      ],
      "metadata": {
        "hidden": true,
        "id": "7FyhpOzRJpni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ejemplo, quizás hayamos medido la altura sobre el suelo de un objeto antes y después de algún evento. Las medidas tendrán algún error aleatorio. Podemos usar el generador de números aleatorios de numpy para simular eso. Me gusta usar \"semilla\" cuando escribo sobre simulaciones como esta para saber que verás lo mismo que yo:"
      ],
      "metadata": {
        "id": "9er3q3UoJpni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import normal,seed,uniform\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "5Uisg7IzJpni"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a function `add_noise` that adds some random variation to an array:"
      ],
      "metadata": {
        "hidden": true,
        "id": "s8pos5c8Jpni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí hay una función `add_noise` que agrega alguna variación aleatoria a una matriz:"
      ],
      "metadata": {
        "id": "Ar5fHxHPJpni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(x, scale): return normal(scale=scale, size=x.shape)\n",
        "def add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "STFe14fjJpni"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use it to simulate some measurements evenly distributed over time:"
      ],
      "metadata": {
        "hidden": true,
        "id": "VEQ840z9Jpni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usémoslo para simular algunas medidas distribuidas uniformemente en el tiempo:"
      ],
      "metadata": {
        "id": "8N8LC1f2Jpni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-2, 2, num=20)[:,None]\n",
        "y = add_noise(f(x), 0.2, 1.3)\n",
        "plt.scatter(x,y);"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "sPl2R6WiJpni"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now <b>let's see what happens if we *underfit* or *overfit* these predictions</b>. To do that, we'll create a function that fits a polynomial of some degree (e.g. a line is degree 1, quadratic is degree 2, cubic is degree 3, etc). The details of how this function works don't matter too much so feel free to skip over it if you like!  (PS: if you're not sure about the jargon around polynomials, here's a [great video](https://www.youtube.com/watch?v=ffLLmV4mZwU) which teaches you what you'll need to know.)"
      ],
      "metadata": {
        "hidden": true,
        "id": "fi5jL7toJpni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora <b>veamos qué sucede si *subajustamos* o *sobreajustamos* estas predicciones</b>. Para hacer eso, crearemos una función que se ajuste a un polinomio de algún grado (por ejemplo, una línea es de grado 1, una cuadrática es de grado 2, una cúbica es de grado 3, etc.). Los detalles de cómo funciona esta función no importan demasiado, así que siéntete libre de omitirlos si lo deseas. (PD: si no estás seguro de la jerga relacionada con los polinomios, aquí tienes un [excelente vídeo](https://www.youtube.com/watch?v=ffLLmV4mZwU) que te enseña lo que necesitas saber)."
      ],
      "metadata": {
        "id": "-vQWRzIMJpni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def plot_poly(degree):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(x, y)\n",
        "    plt.scatter(x,y)\n",
        "    plot_function(model.predict)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "eYEpuJyGJpnj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, what happens if we fit a line (a \"degree 1 polynomial\") to our measurements?"
      ],
      "metadata": {
        "hidden": true,
        "id": "77uBypANJpnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_poly(1)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "mHeBVz9JJpnj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, <span style=\"color:red\">the points on the red line (the line we fitted) aren't very close at all. This is <b>*under-fit* -- there's not enough detail in our function to match our data.</b></span>\n",
        "\n",
        "And what happens if we fit a degree 10 polynomial to our measurements?"
      ],
      "metadata": {
        "hidden": true,
        "id": "udK7ZO4jJpnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como puedes ver, <span style=\"color:red\">los puntos en la línea roja (la línea que ajustamos) no están muy cerca. Esto es <b>*under-fit*: no hay suficientes detalles en nuestra función para coincidir con nuestros datos.</b></span>\n",
        "\n"
      ],
      "metadata": {
        "id": "MmSJeaX0Jpnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_poly(10)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "AIk2C5ppJpnj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well now it fits our data better, <span style=\"color:red\">but it doesn't look like it'll do a great job predicting points other than those we measured -- especially those in earlier or later time periods. <b>This is *over-fit* -- there's too much detail such that the model fits our points, but not the underlying process we really care about.</b></span>\n",
        "\n",
        "Let's try a degree 2 polynomial (a quadratic), and compare it to our \"true\" function (in blue):"
      ],
      "metadata": {
        "hidden": true,
        "id": "r5rEryZlJpnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bueno, ahora se ajusta mejor a nuestros datos, <span style=\"color:red\">pero no parece que vaya a hacer un gran trabajo al predecir puntos distintos a los que medimos, especialmente aquellos en períodos de tiempo anteriores o posteriores. <b>Esto es *sobreajuste*: hay demasiados detalles como para que el modelo se ajuste a nuestros puntos, pero no al proceso subyacente que realmente nos importa.</b></span>\n",
        "\n",
        "Probemos con un polinomio de grado 2 (un cuadrático) y compárelo con nuestra función \"verdadera\" (en azul):"
      ],
      "metadata": {
        "id": "ss1H4lfwJpnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_poly(2)\n",
        "plot_function(f, color='b')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "_2NU14kLJpnj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not bad at all!\n",
        "\n",
        "<span style=\"color:blue\">So, how do we recognise whether our models are under-fit, over-fit, or \"just right\"? We use a <b>*validation set*</b>. This is a set of data that we \"hold out\" from training -- we don't let our model see it at all</span>. If you use the fastai library, it automatically creates a validation set for you if you don't have one, and will always report metrics (measurements of the accuracy of a model) using the validation set.\n",
        "\n",
        "The validation set is *only* ever used to see how we're doing. It's *never* used as inputs to training the model.\n",
        "\n",
        "Transformers uses a `DatasetDict` for holding your training and validation sets. To create one that contains 25% of our data for the validation set, and 75% for the training set, use `train_test_split`:"
      ],
      "metadata": {
        "hidden": true,
        "id": "j_SX8AlXJpnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Eso no está nada mal!\n",
        "\n",
        "<span style=\"color:blue\">Entonces, ¿cómo reconocemos si nuestros modelos no están bien ajustados, demasiado ajustados o son \"perfectos\"? Usamos un <b>*conjunto de validación*</b>. Este es un conjunto de datos que \"ocultamos\" del entrenamiento; no dejamos que nuestro modelo los vea en absoluto</span>. Si usa la biblioteca fastai, crea automáticamente un conjunto de validación si no tiene uno, y siempre informará métricas (medidas de la precisión de un modelo) utilizando el conjunto de validación.\n",
        "\n",
        "El conjunto de validación *sólo* se utiliza para ver cómo lo estamos haciendo. *Nunca* se utiliza como entrada para entrenar el modelo.\n",
        "\n",
        "Transformers utiliza un `DatasetDict` para guardar sus conjuntos de entrenamiento y validación. Para crear uno que contenga el 25% de nuestros datos para el conjunto de validación y el 75% para el conjunto de entrenamiento, use `train_test_split`:"
      ],
      "metadata": {
        "id": "oHg7BPcqJpnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "Bce-68_OJpnk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>As you see above, the validation set here is called `test` and not `validate`, so be careful!</b>\n",
        "\n",
        "<span style=\"color:red\">In practice, a random split like we've used here might not be a good idea</span> -- here's what Dr Rachel Thomas has to say about it:\n",
        "\n",
        "> <i>\"<span style=\"color:red\">One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all)</span>. Depending on the nature of your data, choosing a validation set can be the most important step. <span style=\"color:red\">Although sklearn offers a `train_test_split` method, this method takes a random subset of the data, which is a poor choice for many real-world problems.</span>\"</i>\n",
        "\n",
        "<b>I strongly recommend reading her article [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/) to more fully understand this critical topic.</b>"
      ],
      "metadata": {
        "hidden": true,
        "id": "gzGvlVxZJpnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Como puede ver arriba, la validación configurada aquí se llama `prueba` y no `validación`, ¡así que tenga cuidado!</b>\n",
        "\n",
        "<span style=\"color:red\">En la práctica, una división aleatoria como la que hemos usado aquí podría no ser una buena idea</span>. Esto es lo que la Dra. Rachel Thomas tiene que decir al respecto:\n",
        "\n",
        "> <i>\"<span style=\"color:red\">Uno de los culpables más probables de esta desconexión entre los resultados en desarrollo y los resultados en producción es un conjunto de validación mal elegido (o peor aún, ningún conjunto de validación) </span>. Dependiendo de la naturaleza de sus datos, elegir un conjunto de validación puede ser el paso más importante. <span style=\"color:red\">Aunque sklearn ofrece un método `train_test_split`, este método toma un subconjunto aleatorio de los datos, lo cual es una mala elección para muchos problemas del mundo real.</span>\"</i>\n",
        "\n",
        "<b>Recomiendo encarecidamente leer su artículo [Cómo (y por qué) crear un buen conjunto de validación](https://www.fast.ai/2017/11/13/validation-sets/) para comprender mejor esta cuestión crítica. tema.</b>"
      ],
      "metadata": {
        "id": "svGiPBq4Jpnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test set"
      ],
      "metadata": {
        "heading_collapsed": true,
        "id": "2Bqz7fPuJpnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So that's the validation set explained, and created. What about the \"test set\" then -- what's that for?\n",
        "\n",
        "<span style=\"color:blue\"><b>The *test set* is yet another dataset that's held out from training. But it's held out from reporting metrics too! The accuracy of your model on the test set is only ever checked after you've completed your entire training process, including trying different models, training methods, data processing, etc.</b></span>\n",
        "\n",
        "You see, as you try all these different things, to see their impact on the metrics on the validation set, you might just accidentally find a few things that entirely coincidentally improve your validation set metrics, but aren't really better in practice. Given enough time and experiments, you'll find lots of these coincidental improvements. That means you're actually over-fitting to your validation set!\n",
        "\n",
        "That's why we keep a test set held back. Kaggle's public leaderboard is like a test set that you can check from time to time. But don't check too often, or you'll be even over-fitting to the test set!\n",
        "\n",
        "Kaggle has a *second* test set, which is yet another held-out dataset that's only used at the *end* of the competition to assess your predictions. That's called the \"private leaderboard\". Here's a [great post](https://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/) about what can happen if you overfit to the public leaderboard.\n",
        "\n",
        "<b>We'll use `eval` as our name for the test set, to avoid confusion with the `test` dataset that was created above.</b>"
      ],
      "metadata": {
        "hidden": true,
        "id": "P4wQKl08Jpnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así que ese es el conjunto de validación explicado y creado. ¿Qué pasa entonces con el \"conjunto de prueba\"? ¿Para qué sirve?\n",
        "\n",
        "<span style=\"color:blue\"><b>El *conjunto de prueba* es otro conjunto de datos que no se incluye en el entrenamiento. ¡Pero también queda fuera de las métricas de informes! La precisión de su modelo en el conjunto de prueba solo se verifica después de haber completado todo el proceso de capacitación, incluida la prueba de diferentes modelos, métodos de capacitación, procesamiento de datos, etc.</b></span>\n",
        "\n",
        "Verá, a medida que prueba todas estas cosas diferentes, para ver su impacto en las métricas del conjunto de validación, es posible que accidentalmente encuentre algunas cosas que mejoren por coincidencia las métricas de su conjunto de validación, pero que en realidad no son mejores en la práctica. Con suficiente tiempo y experimentos, encontrará muchas de estas mejoras coincidentes. ¡Eso significa que en realidad te estás adaptando demasiado a tu conjunto de validación!\n",
        "\n",
        "Por eso mantenemos un equipo de prueba retenido. La tabla de clasificación pública de Kaggle es como un conjunto de pruebas que puedes consultar de vez en cuando. ¡Pero no lo revises con demasiada frecuencia, o incluso te sobreajustarás al equipo de prueba!\n",
        "\n",
        "Kaggle tiene un *segundo* conjunto de pruebas, que es otro conjunto de datos retenido que solo se utiliza al *final* de la competencia para evaluar sus predicciones. Eso se llama \"clasificación privada\". Aquí hay una [excelente publicación](https://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/) sobre lo que puede suceder si sobrepasas la clasificación pública.\n",
        "\n",
        "<b>Usaremos `eval` como nombre para el conjunto de prueba, para evitar confusiones con el conjunto de datos `test` que se creó anteriormente.</b>"
      ],
      "metadata": {
        "id": "_AOBPDKqJpnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "HLJt-tPGJpnl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics and correlation"
      ],
      "metadata": {
        "heading_collapsed": true,
        "id": "Nm_NHw7CJpnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\">When we're training a model, there will be one or more *metrics* that we're interested in maximising or minimising. These are the measurements that should, hopefully, represent how well our model will works for us.</span>\n",
        "\n",
        "<span style=\"color:red\">In real life, outside of Kaggle, things not easy... As my partner Dr Rachel Thomas notes in [The problem with metrics is a big problem for AI](https://www.fast.ai/2019/09/24/metrics/)</span>:\n",
        "\n",
        ">  At their heart, what most current AI approaches do is to optimize metrics. The practice of optimizing metrics is not new nor unique to AI, yet AI can be particularly efficient (even too efficient!) at doing so. This is important to understand, <span style=\"color:red\">because any risks of optimizing metrics are heightened by AI</span>. While metrics can be useful in their proper place, <span style=\"color:red\">there are harms when they are unthinkingly applied. Some of the scariest instances of algorithms run amok all result from over-emphasizing metrics</span>. <span style=\"color:blue\">We have to understand this dynamic in order to understand the urgent risks we are facing due to misuse of AI</span>.\n",
        "\n",
        "In Kaggle, however, it's very straightforward to know what metric to use: Kaggle will tell you! According to this competition's [evaluation page](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview/evaluation), \"*submissions are evaluated on the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between the predicted and actual similarity scores*.\" This coefficient is usually abbreviated using the single letter *r*. It is the most widely used measure of the degree of relationship between two variables.\n",
        "\n",
        "r can vary between `-1`, which means perfect inverse correlation, and `+1`, which means perfect positive correlation. <span style=\"color:blue\">The mathematical formula for it is much less important than <b>getting a good intuition</b> for what the different values look like</span>. To start to get that intuition, let's look at some examples using the [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) dataset, which shows \"*is the median house value for California districts, expressed in hundreds of thousands of dollars*\". This dataset is provided by the excellent [scikit-learn](https://scikit-learn.org/stable/) library, which is the most widely used library for machine learning outside of deep learning."
      ],
      "metadata": {
        "hidden": true,
        "id": "OHfcFrmdJpnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\">Cuando entrenamos un modelo, habrá una o más *métricas* que nos interesará maximizar o minimizar. Estas son las medidas que, con suerte, deberían representar qué tan bien funcionará nuestro modelo para nosotros.</span>\n",
        "\n",
        "<span style=\"color:red\">En la vida real, fuera de Kaggle, las cosas no son fáciles... Como señala mi socia, la Dra. Rachel Thomas, en [El problema con las métricas es un gran problema para la IA](https://www.fast.ai/2019/09/24/metrics/)</span>:\n",
        "\n",
        "> En esencia, lo que hacen la mayoría de los enfoques actuales de IA es optimizar las métricas. La práctica de optimizar métricas no es nueva ni exclusiva de la IA, pero la IA puede ser particularmente eficiente (¡incluso demasiado eficiente!) al hacerlo. Es importante comprender esto, <span style=\"color:red\">porque la IA aumenta los riesgos de optimizar las métricas</span>. Si bien las métricas pueden ser útiles en el lugar que les corresponde, <span style=\"color:red\">hay daños cuando se aplican sin pensar. Algunos de los casos más aterradores de algoritmos que se vuelven locos son el resultado de poner demasiado énfasis en las métricas. <span style=\"color:blue\">Tenemos que comprender esta dinámica para comprender los riesgos urgentes a los que nos enfrentamos debido al uso indebido de la IA</span>.\n",
        "\n",
        "En Kaggle, sin embargo, es muy sencillo saber qué métrica usar: ¡Kaggle te lo dirá! Según la [página de evaluación] de este concurso (https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview/evaluación), \"*las presentaciones se evalúan según el [coeficiente de correlación de Pearson] (https://en.wikipedia.org/wiki/Pearson_correlation_coficient) entre las puntuaciones de similitud previstas y reales*.\" Este coeficiente suele abreviarse utilizando la letra *r*. Es la medida más utilizada del grado de relación entre dos variables.\n",
        "\n",
        "r puede variar entre \"-1\", que significa correlación inversa perfecta, y \"+1\", que significa correlación positiva perfecta. <span style=\"color:blue\">La fórmula matemática es mucho menos importante que <b>tener una buena intuición</b> de cómo se ven los diferentes valores</span>. Para comenzar a tener esa intuición, veamos algunos ejemplos usando el conjunto de datos [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset), que muestra \"*is el valor medio de una vivienda en los distritos de California, expresado en cientos de miles de dólares*\". Este conjunto de datos lo proporciona la excelente biblioteca [scikit-learn](https://scikit-learn.org/stable/), que es la biblioteca más utilizada para el aprendizaje automático fuera del aprendizaje profundo."
      ],
      "metadata": {
        "id": "7rbjUFedJpnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\"><b>Whatever we observe with 1000 random points will be the same with 1 million points. So, no need to plot the entire data for visualization</b></span>."
      ],
      "metadata": {
        "id": "DrDVlSa-Jpnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\"><b>Lo que observemos con 1000 puntos aleatorios será lo mismo con 1 millón de puntos. Por lo tanto, no es necesario trazar todos los datos para su visualización</b></span>."
      ],
      "metadata": {
        "id": "54zIj84gJpnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each row is a demographic info about different district and median house value\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "housing = housing['data'].join(housing['target']).sample(1000, random_state=52)\n",
        "housing.head()"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "-970apR3Jpnm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see all the correlation coefficients for every combination of columns in this dataset by calling `np.corrcoef`:"
      ],
      "metadata": {
        "hidden": true,
        "id": "MkEP8bNsJpnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver todos los coeficientes de correlación para cada combinación de columnas en este conjunto de datos llamando a `np.corrcoef`:"
      ],
      "metadata": {
        "id": "uQFArrD3Jpnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=2, suppress=True)\n",
        "\n",
        "np.corrcoef(housing, rowvar=False)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "adoHtQcqJpnm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This works well when we're getting a bunch of values at once, but it's overkill when we want a single coefficient:"
      ],
      "metadata": {
        "hidden": true,
        "id": "-xxTDkMPJpnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto funciona bien cuando obtenemos varios valores a la vez, pero es excesivo cuando queremos un solo coeficiente:"
      ],
      "metadata": {
        "id": "Z166ZltxJpnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.corrcoef(housing.MedInc, housing.MedHouseVal)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "S2frGcD8Jpnm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, we'll create this little function to just return the single number we need given a pair of variables:"
      ],
      "metadata": {
        "hidden": true,
        "id": "bGCqR843Jpnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por lo tanto, crearemos esta pequeña función para devolver simplemente el número que necesitamos dado un par de variables:"
      ],
      "metadata": {
        "id": "E-VhLYMQJpnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
        "\n",
        "corr(housing.MedInc, housing.MedHouseVal)"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "n1XGk0ImJpnn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll look at a few examples of correlations, using this function (the details of the function don't matter too much):"
      ],
      "metadata": {
        "hidden": true,
        "id": "w5GqGVlnJpnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora veremos algunos ejemplos de correlaciones usando esta función (los detalles de la función no importan demasiado):"
      ],
      "metadata": {
        "id": "HiHUbMY1Jpnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_corr(df, a, b):\n",
        "    x,y = df[a],df[b]\n",
        "    plt.scatter(x,y, alpha=0.5, s=4)\n",
        "    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "z9vO-JXaJpnn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, let's check out the correlation between income and house value:"
      ],
      "metadata": {
        "hidden": true,
        "id": "GbCRYh-IJpno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bien, veamos la correlación entre los ingresos y el valor de la vivienda:"
      ],
      "metadata": {
        "id": "T7eZYsHNJpno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(housing, 'MedInc', 'MedHouseVal')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "dOTOigmQJpno"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "So that's what a correlation of 0.68 looks like. It's quite a close relationship, but there's still a lot of variation. (Incidentally, <span style=\"color:blue\">this also shows why looking at your data is so important -- <span style=\"color:red\">we can see clearly in this plot that house prices above $500,000 seem to have been truncated to that maximum value)</span></span>.\n",
        "\n",
        "Let's take a look at another pair:"
      ],
      "metadata": {
        "hidden": true,
        "id": "0S0W_oVgJpno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así es como se ve una correlación de 0,68. Es una relación bastante estrecha, pero todavía hay mucha variación. (Por cierto, <span style=\"color:blue\">esto también muestra por qué es tan importante mirar sus datos: <span style=\"color:red\">podemos ver claramente en este gráfico que los precios de las viviendas por encima de $500,000 parecen se han truncado a ese valor máximo)</span></span>.\n",
        "\n",
        "Echemos un vistazo a otro par:"
      ],
      "metadata": {
        "id": "PjzrN93BJpno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(housing, 'MedInc', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "ibxU6B5jJpno"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The relationship looks like it is similarly close to the previous example, but <span style=\"color:blue\">r is much lower than the income vs valuation case. Why is that? The reason is that there are a <b>lot of *outliers* -- values of `AveRooms` well outside the mean</b>.</span>\n",
        "\n",
        "<span style=\"color:red\">r is very sensitive to outliers. <b>If there's outliers in your data, then the relationship between them will dominate the metric</b>. In this case, the houses with a very high number of rooms don't tend to be that valuable, so it's decreasing r from where it would otherwise be.</span>\n",
        "\n",
        "<span style=\"color:blue\"><b>Let's remove the outliers</b> and try again:</span>\n",
        "\n",
        "***Note***\n",
        "- <span style=\"color:blue\">Removing the outliers in practice may not be the best way to approach it</span>\n",
        "    - <span style=\"color:blue\">Never delete an outlier without investigating where/why they come from</span>\n",
        "- <span style=\"color:blue\">Rather, clearly from looking at this dataset, these 2 different groups cannot be treated the same way. Probably, we split them into two separate analysis. The concept of outlier exists in statistical sense, but may not be in real sense.</span>"
      ],
      "metadata": {
        "hidden": true,
        "id": "jV_4bE7WJpnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La relación parece similar al ejemplo anterior, pero <span style=\"color:blue\">r es mucho menor que en el caso de ingresos versus valoración. ¿Porqué es eso? La razón es que hay <b>muchos *valores atípicos*: valores de `AveRooms` muy fuera de la media</b>.</span>\n",
        "\n",
        "<span style=\"color:red\">r es muy sensible a los valores atípicos. <b>Si hay valores atípicos en sus datos, la relación entre ellos dominará la métrica</b>. En este caso, las casas con un número muy elevado de habitaciones no suelen ser tan valiosas, por lo que r está disminuyendo desde donde sería de otro modo.</span>\n",
        "\n",
        "<span style=\"color:blue\"><b>Eliminemos los valores atípicos</b> e intentemos de nuevo:</span>\n",
        "\n",
        "***Nota***\n",
        "- <span style=\"color:blue\">Eliminar los valores atípicos en la práctica puede no ser la mejor manera de abordarlo</span>\n",
        "    - <span style=\"color:blue\">Nunca elimines un valor atípico sin investigar de dónde y por qué proviene</span>\n",
        "- <span style=\"color:blue\">Más bien, claramente al observar este conjunto de datos, estos 2 grupos diferentes no pueden tratarse de la misma manera. Probablemente los dividimos en dos análisis separados. El concepto de valor atípico existe en un sentido estadístico, pero puede no existir en un sentido real.</span>"
      ],
      "metadata": {
        "id": "nQEY_q1QJpnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset = housing[housing.AveRooms<15]\n",
        "show_corr(subset, 'MedInc', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "Qb-Wpi0wJpnp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we expected, now the correlation is very similar to our first comparison. <span style=\"color:blue\">Just by removing the outliers (few data points), our r went up from 0.43 to 0.68.\n",
        "\n",
        "Here's another relationship using `AveRooms` on the subset:"
      ],
      "metadata": {
        "hidden": true,
        "id": "3tN3iYgVJpnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como esperábamos, ahora la correlación es muy similar a nuestra primera comparación. <span style=\"color:blue\">Con solo eliminar los valores atípicos (algunos puntos de datos), nuestra r aumentó de 0,43 a 0,68.\n",
        "\n",
        "Aquí hay otra relación que usa `AveRooms` en el subconjunto:"
      ],
      "metadata": {
        "id": "SjLMOFEoJpnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(subset, 'MedHouseVal', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "MXe1XEcEJpnp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this level, with r of 0.34, the relationship is becoming quite weak.\n",
        "\n",
        "Let's look at one more:"
      ],
      "metadata": {
        "hidden": true,
        "id": "oP-T7LoYJpnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este nivel, con r de 0,34, la relación se está volviendo bastante débil.\n",
        "\n",
        "Veamos uno más:"
      ],
      "metadata": {
        "id": "DeDJpQloJpnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(subset, 'HouseAge', 'AveRooms')"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "thfngl9mJpnq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see here, a correlation of -0.2 shows a very weak negative trend.\n",
        "\n",
        "We've seen now examples of a variety of levels of correlation coefficient, so hopefully you're getting a good sense of what this metric means.\n",
        "\n",
        "<b>Transformers (in hugging face) expects metrics to be returned as a `dict`, since that way the trainer knows what label to use</b>, so let's create a function to do that:"
      ],
      "metadata": {
        "hidden": true,
        "id": "6NWVSN3bJpnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Como puede ver aquí, una correlación de -0,2 muestra una tendencia negativa muy débil.\n",
        "\n",
        "Hemos visto ejemplos de una variedad de niveles de coeficiente de correlación, por lo que esperamos que tenga una buena idea de lo que significa esta métrica.\n",
        "\n",
        "<b>Transformers (en hugging face) espera que las métricas se devuelvan como un `dict`, ya que de esa manera el entrenador sabe qué etiqueta usar</b>, así que creemos una función para hacer eso:"
      ],
      "metadata": {
        "id": "zvGOMb4AJpnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
      ],
      "metadata": {
        "hidden": true,
        "trusted": true,
        "id": "Oz4vtPpCJpnq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "euljCU5uJpnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training our model"
      ],
      "metadata": {
        "id": "7AUswe1jJpnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a model in Transformers we'll need this:"
      ],
      "metadata": {
        "id": "X_6GLrYMJpnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer"
      ],
      "metadata": {
        "trusted": true,
        "id": "f5EnMIG-Jpnr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pick a batch size that fits our GPU, and small number of epochs so we can run experiments quickly:\n",
        "\n",
        "In general, larger batch size means faster computations, but also would need larger GPU memory"
      ],
      "metadata": {
        "id": "6DmuOVgzJpnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegimos un tamaño de lote que se ajuste a nuestra GPU y una pequeña cantidad de épocas para poder ejecutar experimentos rápidamente:\n",
        "\n",
        "En general, un tamaño de lote mayor significa cálculos más rápidos, pero también necesitaría mayor memoria de GPU."
      ],
      "metadata": {
        "id": "cxtaZPSyJpnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 128\n",
        "epochs = 4"
      ],
      "metadata": {
        "trusted": true,
        "id": "-EQVpGYOJpnr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\">The most important hyperparameter is the <b>learning rate</b></span>. fastai provides a learning rate finder to help you figure this out, but Transformers doesn't, so you'll just have to use trial and error. <span style=\"color:blue\">The idea is to find the largest value you can (start with some small value, and keep doubling it), but which doesn't result in training failing.</span>"
      ],
      "metadata": {
        "id": "vAw4L3nsJpnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:blue\">El hiperparámetro más importante es la <b>tasa de aprendizaje</b></span>. fastai proporciona un buscador de tasas de aprendizaje para ayudarte a resolver esto, pero Transformers no, por lo que solo tendrás que usar prueba y error. <span style=\"color:blue\">La idea es encontrar el valor más grande que puedas (comienza con un valor pequeño y sigue duplicándolo), pero que no resulte en que el entrenamiento falle.</span>"
      ],
      "metadata": {
        "id": "KVorgvQsJpnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 8e-5"
      ],
      "metadata": {
        "trusted": true,
        "id": "jfbk9SNpJpnr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers uses the `TrainingArguments` class to set up arguments. Don't worry too much about the values we're using here -- they should generally work fine in most cases. It's just the 3 parameters above that you may need to change for different models."
      ],
      "metadata": {
        "id": "dyT4KpkKJpnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers usa la clase `TrainingArguments` para configurar argumentos. No se preocupe demasiado por los valores que estamos usando aquí; generalmente deberían funcionar bien en la mayoría de los casos. Es posible que deba cambiar solo los 3 parámetros anteriores para diferentes modelos."
      ],
      "metadata": {
        "id": "AyJOvEZJJpnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
        "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
        "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
      ],
      "metadata": {
        "trusted": true,
        "id": "sLIJ1fkaJpnr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create our model, and `Trainer`, which is a class which combines the data and model together (just like `Learner` in fastai):"
      ],
      "metadata": {
        "id": "HnMmR5zrJpnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos crear nuestro modelo y \"Entrenador\", que es una clase que combina los datos y el modelo (al igual que \"Aprendiz\" en fastai):"
      ],
      "metadata": {
        "id": "okNr2BEJJpns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (model_nm)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FH23pGzyJpns"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are trying to do classification of sequences. Using `AutoModelForSequenceClassification` will help us to create classification that's appropriate for sequences."
      ],
      "metadata": {
        "id": "CqeYq2urJpns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estamos intentando hacer una clasificación de secuencias. Usar `AutoModelForSequenceClassification` nos ayudará a crear una clasificación apropiada para secuencias."
      ],
      "metadata": {
        "id": "94VVL_LsJpns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
        "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
        "                  tokenizer=tokz, compute_metrics=corr_d)"
      ],
      "metadata": {
        "trusted": true,
        "id": "o4LTkXyOJpns"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, Transformers spits out lots of warnings. You can safely ignore them.\n",
        "\n",
        "Let's train our model!"
      ],
      "metadata": {
        "id": "DSL9KVqvJpns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como puede ver, Transformers lanza muchas advertencias. Puedes ignorarlos con seguridad.\n",
        "\n",
        "¡Entrenemos a nuestro modelo!"
      ],
      "metadata": {
        "id": "_0yRRoTIJpns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train();"
      ],
      "metadata": {
        "trusted": true,
        "id": "u_UA8GxRJpns"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lots more warning from Transformers again -- you can ignore these as before.\n",
        "\n",
        "The key thing to <b>look at is the \"Pearson\" value in table above. As you see, it's increasing, and is already above 0.8. That's great news!</b> We can now submit our predictions to Kaggle if we want them to be scored on the official leaderboard. Let's get some predictions on the test set:"
      ],
      "metadata": {
        "id": "6V_tzSawJpnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Muchas más advertencias de Transformers nuevamente: puedes ignorarlas como antes.\n",
        "\n",
        "La clave a tener en cuenta es el valor \"Pearson\" en la tabla anterior. Como veis, está aumentando y ya está por encima de 0,8. ¡Es una gran noticia!</b> Ahora podemos enviar nuestras predicciones a Kaggle si queremos que se puntúen en la clasificación oficial. Consigamos algunas predicciones sobre el conjunto de prueba:"
      ],
      "metadata": {
        "id": "skupC3mvJpnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (eval_ds.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_SyrxtDTJpnt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
        "preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "f52vCxL3Jpnt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:red\">Look out - some of our predictions are <0, or >1! </span><span style=\"color:blue\">This once again shows the value of remember to <b>actually *look* at your data</b>. Let's fix those out-of-bounds predictions:</span>"
      ],
      "metadata": {
        "id": "28rsZBI5Jpnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span style=\"color:red\">Cuidado: ¡algunas de nuestras predicciones son <0 o >1! </span><span style=\"color:blue\">Esto muestra una vez más el valor de recordar <b>realmente *mira* tus datos</b>. Arreglemos esas predicciones fuera de límites:</span>"
      ],
      "metadata": {
        "id": "3Ce28PsuJpnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.clip(preds, 0, 1) # However, there are better ways to do it than \"clip\""
      ],
      "metadata": {
        "trusted": true,
        "id": "HhAkvrtmJpnt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides, we should have predicted categories instead of a continuous value, which was the requirement for the competition. This can be achieved using `sigmoid` function and few other techniques which will be covered in the following modules"
      ],
      "metadata": {
        "id": "-bp8HgiDJpnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, deberíamos haber predicho categorías en lugar de un valor continuo, que era el requisito para la competición. Esto se puede lograr usando la función \"sigmoidea\" y algunas otras técnicas que se cubrirán en los siguientes módulos."
      ],
      "metadata": {
        "id": "tKeNe16oJpnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "KoRk9zR8Jpnu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, now we're ready to create our submission file. If you save a CSV in your notebook, you will get the option to submit it later."
      ],
      "metadata": {
        "id": "XLsTxFKxJpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bien, ahora estamos listos para crear nuestro archivo de envío. Si guarda un CSV en su cuaderno, tendrá la opción de enviarlo más tarde.\n",
        "\n"
      ],
      "metadata": {
        "id": "t_2aEz4oJpnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "submission = datasets.Dataset.from_dict({\n",
        "    'id': eval_ds['id'],\n",
        "    'score': preds\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CWv7MzKcJpnu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately this is a *code competition* and internet access is disabled. That means the `pip install datasets` command we used above won't work if you want to submit to Kaggle. To fix this, you'll need to download the pip installers to Kaggle first, as [described here](https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195). Once you've done that, disable internet in your notebook, go to the Kaggle leaderboards page, and click the *Submission* button."
      ],
      "metadata": {
        "id": "QqNWAO4oJpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lamentablemente, esta es una *competencia de códigos* y el acceso a Internet está deshabilitado. Eso significa que el comando `pip install datasets` que usamos anteriormente no funcionará si desea enviarlo a Kaggle. Para solucionar este problema, primero deberá descargar los instaladores de pip en Kaggle, como [se describe aquí] (https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195). Una vez que haya hecho eso, desactive Internet en su computadora portátil, vaya a la página de tablas de clasificación de Kaggle y haga clic en el botón *Enviar*"
      ],
      "metadata": {
        "id": "NQcM4eq5Jpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The end"
      ],
      "metadata": {
        "id": "aUw1CDvRJpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you're ready to go deeper, take a look at my [Iterate Like a Grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/) notebook.\n",
        "\n",
        "Thanks for reading! This has been a bit of an experiment for me -- I've never done an \"absolute beginners\" guide before on Kaggle. I hope you like it! If you do, I'd greatly appreciate an upvote. Don't hesitate to add a comment if you have any questions or thoughts to add."
      ],
      "metadata": {
        "id": "YNYXdq-CJpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que esté listo para profundizar, eche un vistazo a mi cuaderno [Iterar como un gran maestro](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/).\n",
        "\n",
        "¡Gracias por leer! Esto ha sido una especie de experimento para mí: nunca antes había hecho una guía para \"principiantes absolutos\" en Kaggle. ¡Espero que te guste! Si es así, agradecería mucho un voto a favor. No dude en agregar un comentario si tiene alguna pregunta o idea que agregar."
      ],
      "metadata": {
        "id": "xLxtdwCFJpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further readups and clarifications\n",
        "## Readups and Practicies\n",
        "- Once you're ready to go deeper, take a look at my [Iterate Like a Grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/) notebook.\n",
        "- [Researching public comments for FCC Proceeding 17-108 (Net Neutrality Repeal)](https://github.com/j2kao/fcc_nn_research) notebook and data.\n",
        "- [How (and why) to create a good validation set](https://www.fast.ai/posts/2017-11-13-validation-sets.html)\n",
        "- [The problem with metrics is a big problem for AI](https://www.fast.ai/posts/2019-09-24-metrics.html)\n",
        "- [The dangers of overfitting: a Kaggle postmortem](https://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/)\n",
        "\n",
        "## Clarifications\n",
        "- What does `AutoModelForSequenceClassification` do?"
      ],
      "metadata": {
        "id": "u1k3vJVqJpnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Más lecturas y aclaraciones.\n",
        "## Lecturas y prácticas\n",
        "- Una vez que estés listo para profundizar, echa un vistazo a mi cuaderno [Iterate Like a Grandmaster](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/).\n",
        "- [Investigación de comentarios públicos para el Procedimiento 17-108 de la FCC (Derogación de la Neutralidad de la Red)](https://github.com/j2kao/fcc_nn_research) cuaderno y datos.\n",
        "- [Cómo (y por qué) crear un buen conjunto de validación](https://www.fast.ai/posts/2017-11-13-validation-sets.html)\n",
        "- [El problema de las métricas es un gran problema para la IA](https://www.fast.ai/posts/2019-09-24-metrics.html)\n",
        "- [Los peligros del sobreajuste: una autopsia de Kaggle](https://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/)\n",
        "\n",
        "## Aclaraciones\n",
        "- ¿Qué hace `AutoModelForSequenceClassification`?"
      ],
      "metadata": {
        "id": "PRIfvQSJJpnv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "gwMpsCTnJpnv"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}