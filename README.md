# ğŸ“š NLP Aprendizaje en EspaÃ±ol con Hugging Face Transformers

## ğŸ¯ Objetivo
Este repositorio es un plan de **8 semanas** para aprender Procesamiento de Lenguaje Natural (NLP) **en espaÃ±ol** usando la librerÃ­a [ğŸ¤— Hugging Face Transformers](https://github.com/huggingface/transformers) y datasets en espaÃ±ol.  
El aprendizaje estÃ¡ optimizado para un horario de estudio **de 6:00 AM a 10:00 AM**.

---

## ğŸ“‚ Estructura del repositorio

nlp-aprendizaje/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ Hugging Face Transformers/
â”‚ â”œâ”€â”€ 1_pipeline_basico.ipynb
â”‚ â”œâ”€â”€ 2_tokenizacion.ipynb
â”‚ â”œâ”€â”€ 3_datasets_tass2020.ipynb
â”‚ â”œâ”€â”€ 4_trainer_beto.ipynb
â”‚ â”œâ”€â”€ 5_traduccion_marianmt.ipynb
â”‚ â”œâ”€â”€ 6_whisper_transcripcion.ipynb
â”‚ â”œâ”€â”€ 7_blip_captioning.ipynb
â”‚ â””â”€â”€ 8_proyecto_final.ipynb
â”‚
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ text_cleaning.py
â”‚
â”œâ”€â”€ app_streamlit/
â”‚ â”œâ”€â”€ app.py
â”‚ â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md


---

## ğŸ“… Plan de estudio â€“ 8 semanas

| Semana | Notebook | Objetivo |
|--------|----------|----------|
| 1 | `1_pipeline_basico.ipynb` | Uso de modelos pre-entrenados con `pipeline`. |
| 2 | `2_tokenizacion.ipynb` | TokenizaciÃ³n y tensores. |
| 3 | `3_datasets_tass2020.ipynb` | Cargar y explorar datasets en espaÃ±ol. |
| 4 | `4_trainer_beto.ipynb` | Entrenar BETO para sentimientos. |
| 5 | `5_traduccion_marianmt.ipynb` | Traducir ESâ†”EN con MarianMT. |
| 6 | `6_whisper_transcripcion.ipynb` | Transcribir audio en espaÃ±ol con Whisper. |
| 7 | `7_blip_captioning.ipynb` | Captioning de imÃ¡genes. |
| 8 | `8_proyecto_final.ipynb` | Audio â†’ resumen â†’ traducciÃ³n. |

---

## ğŸ—‚ Datasets usados

| Tarea | Dataset | Link HF Datasets |
|-------|---------|------------------|
| Sentimientos | TASS 2020 | `PlanTL-GOB-ES/tass2020` |
| Pregunta-Respuesta | SQuAD-es | `mrm8488/spanbert-finetuned-squades-spanish` |
| TraducciÃ³n | MarianMT ESâ†”EN | `Helsinki-NLP/opus-mt-es-en` / `Helsinki-NLP/opus-mt-en-es` |
| Audio | WHISPER | `openai/whisper-small` |
| Multimodal | BLIP | `Salesforce/blip-image-captioning-base` |

---

## â° Horario diario recomendado (6:00 AM â€“ 10:00 AM)

**Bloque 1 â€“ 6:00 AM a 7:30 AM (90 min)**  
ğŸ“– TeorÃ­a + ejecuciÃ³n guiada de la semana.  

**Descanso â€“ 7:30 AM a 7:45 AM (15 min)**  

**Bloque 2 â€“ 7:45 AM a 9:15 AM (90 min)**  
ğŸ’» PrÃ¡ctica aplicada: modificar parÃ¡metros y datasets.  

**Descanso â€“ 9:15 AM a 9:30 AM (15 min)**  

**Bloque 3 â€“ 9:30 AM a 10:00 AM (30 min)**  
ğŸ“ Documentar lo aprendido.

---

## ğŸš€ Ejecutar notebooks
1. Clonar el repo:  

git clone https://github.com/Gman80/nlp-aprendizaje.git
cd nlp-aprendizaje

2. Abrir el notebook de la semana en **Google Colab** o **Jupyter Notebook**.
3. Seguir las instrucciones de cada notebook.

---

## ğŸ’¡ Consejos
- Prepara el entorno la noche anterior.
- Desayuna ligero antes de iniciar.
- Guarda tus modificaciones y haz `git push` semanalmente.

âœ **Autor:** Gman80  
ğŸ“† **Plan optimizado:** Agosto 2025  

